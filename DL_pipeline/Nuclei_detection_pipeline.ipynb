{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4yWFoJNnoin"
      },
      "source": [
        "# **1. Initialise the Colab session**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMNHVZfHmbKb"
      },
      "source": [
        "\n",
        "## **1.1. Check for GPU access**\n",
        "---\n",
        "\n",
        "By default, the session should be using Python 3 and GPU acceleration, but it is possible to ensure that these are set properly by doing the following:\n",
        "\n",
        "<font size = 4>Go to **Runtime -> Change the Runtime type**\n",
        "\n",
        "<font size = 4>**Runtime type: Python 3** *(Python 3 is programming language in which this program is written)*\n",
        "\n",
        "<font size = 4>**Accelator: GPU** *(Graphics processing unit)*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zCvebubeSaGY"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Run this cell to check if you have GPU access\n",
        "\n",
        "import tensorflow as tf\n",
        "if tf.test.gpu_device_name()=='':\n",
        "  print('You do not have GPU access.')\n",
        "  print('Did you change your runtime ?')\n",
        "  print('If the runtime setting is correct then Google did not allocate a GPU for your session')\n",
        "  print('Expect slow performance. To access GPU try reconnecting later')\n",
        "\n",
        "else:\n",
        "  print('You have GPU access')\n",
        "  !nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNIVx8_CLolt"
      },
      "source": [
        "## **1.2. Mount your Google Drive**\n",
        "---\n",
        "<font size = 4> To use this notebook on the data present in your Google Drive, you need to mount your Google Drive to this notebook.\n",
        "\n",
        "<font size = 4> Play the cell below to mount your Google Drive and follow the link. In the new browser window, select your drive and select 'Allow', copy the code, paste into the cell and press enter. This will give Colab access to the data on the drive.\n",
        "\n",
        "<font size = 4> Once this is done, your data are available in the **Files** tab on the top left of notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "01Djr8v-5pPk"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play the cell to connect your Google Drive to Colab\n",
        "\n",
        "\n",
        "\n",
        "# mount user's Google Drive to Google Colab.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdN8B91xZO0x"
      },
      "source": [
        "# **2. Install StarDist, Cellpose, Pix2pix and dependencies**\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fq21zJVFNASx"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@markdown ##StarDist, Cellpose, Pix2pix, and dependencies\n",
        "\n",
        "\n",
        "# Install packages which are not included in Google Colab\n",
        "\n",
        "#!pip uninstall -y -q yellowbrick\n",
        "#!pip install \"opencv-python-headless<4.3\"\n",
        "\n",
        "#!pip install pyopencl\n",
        "\n",
        "!pip install -q tifffile # contains tools to operate tiff-files\n",
        "!pip install -q folium==0.2.1\n",
        "!pip install -q imgaug==0.2.5\n",
        "\n",
        "!pip install -q PTable # Nice tables\n",
        "!pip install -q zarr\n",
        "!pip install -q imagecodecs\n",
        "\n",
        "!pip install -q wget\n",
        "!pip install -q memory_profiler\n",
        "!pip install -q fpdf2\n",
        "\n",
        "\n",
        "!pip install -q csbdeep  # contains tools for restoration of fluorescence microcopy images (Content-aware Image Restoration, CARE). It uses Keras and Tensorflow.\n",
        "!pip install -q stardist # contains tools to operate STARDIST.\n",
        "!pip install -q gputools # improves STARDIST performances\n",
        "\n",
        "\n",
        "\n",
        "%load_ext memory_profiler\n",
        "\n",
        "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n",
        "\n",
        "import os\n",
        "os.chdir('pytorch-CycleGAN-and-pix2pix/')\n",
        "!pip install -r requirements.txt\n",
        "!pip install fpdf\n",
        "\n",
        "#Force session restart\n",
        "#exit(0)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "W-KNaNZ87lnw"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Load the dependencies and functions\n",
        "from __future__ import print_function, unicode_literals, absolute_import, division\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)\n",
        "print(\"Tensorflow enabled.\")\n",
        "\n",
        "import imagecodecs\n",
        "\n",
        "# ------- Variable specific to Stardist -------\n",
        "from stardist import fill_label_holes, random_label_cmap, calculate_extents, gputools_available, relabel_image_stardist, random_label_cmap,  relabel_image_stardist, _draw_polygons, export_imagej_rois\n",
        "from stardist.models import Config2D, StarDist2D, StarDistData2D # import objects\n",
        "from stardist.matching import matching_dataset\n",
        "from csbdeep.utils import Path, normalize, download_and_extract_zip_file, plot_history # for loss plot\n",
        "from csbdeep.io import save_tiff_imagej_compatible\n",
        "%matplotlib inline\n",
        "\n",
        "lbl_cmap = random_label_cmap()\n",
        "\n",
        "import glob\n",
        "import os.path\n",
        "import os\n",
        "import re\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import zarr\n",
        "from zipfile import ZIP_DEFLATED\n",
        "from csbdeep.data import Normalizer, normalize_mi_ma\n",
        "import imagecodecs\n",
        "\n",
        "class MyNormalizer(Normalizer):\n",
        "    def __init__(self, mi, ma):\n",
        "            self.mi, self.ma = mi, ma\n",
        "    def before(self, x, axes):\n",
        "        return normalize_mi_ma(x, self.mi, self.ma, dtype=np.float32)\n",
        "    def after(*args, **kwargs):\n",
        "        assert False\n",
        "    @property\n",
        "    def do_after(self):\n",
        "        return False\n",
        "\n",
        "# ------- Common variable to all ZeroCostDL4Mic notebooks -------\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import urllib\n",
        "import shutil\n",
        "from tifffile import imread, imsave\n",
        "import time\n",
        "import wget\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import csv\n",
        "#from skimage import io\n",
        "from skimage import io, color, filters, morphology, segmentation\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from skimage.util import img_as_uint\n",
        "import matplotlib as mpl\n",
        "from skimage.metrics import structural_similarity\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from astropy.visualization import simple_norm\n",
        "from skimage import img_as_float32, img_as_ubyte, img_as_float\n",
        "from skimage.util import img_as_ubyte\n",
        "from tqdm import tqdm\n",
        "from fpdf import FPDF, HTMLMixin\n",
        "from datetime import datetime\n",
        "from pip._internal.operations.freeze import freeze\n",
        "import subprocess\n",
        "\n",
        "# For sliders and dropdown menu and progress bar\n",
        "from ipywidgets import interact\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Colors for the warning messages\n",
        "class bcolors:\n",
        "  WARNING = '\\033[31m'\n",
        "W  = '\\033[0m'  # white (normal)\n",
        "R  = '\\033[31m' # red\n",
        "\n",
        "import imageio\n",
        "from skimage import data\n",
        "from skimage import exposure\n",
        "from skimage.exposure import match_histograms\n",
        "import os.path\n",
        "\n",
        "\n",
        "# ------- Common variable to all ZeroCostDL4Mic notebooks -------\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import urllib\n",
        "import os, random\n",
        "import shutil\n",
        "import zipfile\n",
        "from tifffile import imread, imsave\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import csv\n",
        "from glob import glob\n",
        "from scipy import signal\n",
        "from scipy import ndimage\n",
        "from skimage import io\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from skimage.util import img_as_uint\n",
        "import matplotlib as mpl\n",
        "from skimage.metrics import structural_similarity\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from astropy.visualization import simple_norm\n",
        "from skimage import img_as_float32\n",
        "from skimage.util import img_as_ubyte\n",
        "from tqdm import tqdm\n",
        "from fpdf import FPDF, HTMLMixin\n",
        "from datetime import datetime\n",
        "import subprocess\n",
        "from pip._internal.operations.freeze import freeze\n",
        "from skimage import data\n",
        "from skimage import filters\n",
        "\n",
        "# ------- Variable specific to Cellpose -------\n",
        "\n",
        "from urllib.parse import urlparse\n",
        "%matplotlib inline\n",
        "from skimage.util import img_as_ubyte\n",
        "import cv2\n",
        "from ipywidgets import interact, interact_manual\n",
        "from zipfile import ZIP_DEFLATED\n",
        "\n",
        "\n",
        "# For sliders and dropdown menu and progress bar\n",
        "from ipywidgets import interact\n",
        "import ipywidgets as widgets\n",
        "\n",
        "\n",
        "# ------- Variable specific to watershed -------\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import ndimage as ndi\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import ndimage as ndi\n",
        "\n",
        "from skimage.segmentation import watershed\n",
        "from skimage.feature import peak_local_max\n",
        "\n",
        "\n",
        "# Download the StarDist model\n",
        "\n",
        "pretrained_model_name = \"2D_versatile_fluo\"\n",
        "pretrained_model_path = \"/content/\"+pretrained_model_name\n",
        "\n",
        "if os.path.exists(pretrained_model_path):\n",
        "  shutil.rmtree(pretrained_model_path)\n",
        "os.makedirs(pretrained_model_path)\n",
        "\n",
        "wget.download(\"https://cloud.mpi-cbg.de/index.php/s/1k5Zcy7PpFWRb0Q/download?path=/versatile&files=2D_versatile_fluo.zip\", pretrained_model_path)\n",
        "\n",
        "with zipfile.ZipFile(pretrained_model_path+\"/2D_versatile_fluo.zip\", 'r') as zip_ref:\n",
        "  zip_ref.extractall(pretrained_model_path)\n",
        "\n",
        "h5_file_path = os.path.join(pretrained_model_path, \"weights_best.h5\")\n",
        "\n",
        "\n",
        "# StarDist prediction function\n",
        "\n",
        "def stardist(video, Saving_folder, model_name, model_path):\n",
        "\n",
        "  # normalize channels independently\n",
        "  axis_norm = (0,1)\n",
        "  model = StarDist2D(None, name = model_name, basedir = model_path)\n",
        "\n",
        "  Number_of_nuclei_list = []\n",
        "  Number_of_frame_list = []\n",
        "  video = normalize(video, 1,99.8, axis=(0,)+tuple(1+np.array(axis_norm)))\n",
        "\n",
        "  n_timepoint = video.shape[0]\n",
        "  prediction_stack = np.zeros((n_timepoint, video.shape[1], video.shape[2]), dtype=np.float32)\n",
        "\n",
        "# Analyse each time points one after the other\n",
        "\n",
        "  for t in range(n_timepoint):\n",
        "    img_t = video[t]\n",
        "    labels, polygons = model.predict_instances(img_t)\n",
        "    prediction_stack[t] = labels\n",
        "    Nuclei_array = polygons['coord']\n",
        "    Nuclei_array2 = [str(t), Nuclei_array.shape[0]]\n",
        "    Number_of_nuclei_list.append(Nuclei_array2)\n",
        "    Number_of_frame_list.append(t)\n",
        "\n",
        "  prediction_stack = img_as_float32(prediction_stack, force_copy=False)\n",
        "\n",
        "# Export a csv file containing the number of nuclei detected at each frame\n",
        "  my_df = pd.DataFrame(Number_of_nuclei_list)\n",
        "  my_df.to_csv(Saving_folder+'/'+str(short_name[0])+'_Nuclei_number.csv', index=False, header=False)\n",
        "  os.chdir(Saving_folder)\n",
        "  imsave(str(short_name[0])+\".tif\", prediction_stack, compression ='zlib')\n",
        "\n",
        "\n",
        "  # Object detected vs frame number\n",
        "  plt.figure(figsize=(20,5))\n",
        "  my_df.plot()\n",
        "  plt.title('Number of objects vs frame number')\n",
        "  plt.ylabel('Number of detected objects')\n",
        "  plt.xlabel('Frame number')\n",
        "  plt.legend()\n",
        "  plt.savefig(Saving_folder+'/'+str(short_name[0])+'_Object_detected_vs_frame_number.png',bbox_inches='tight',pad_inches=0)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "# Pix2pix prepare the data function\n",
        "\n",
        "def pix2pix_prepare_data(timelapse):\n",
        "  n_timepoint = timelapse.shape[0]\n",
        "  for t in range(n_timepoint):\n",
        "    img_t = timelapse[t]\n",
        "    img_t = exposure.equalize_adapthist(img_t, clip_limit=0.03)\n",
        "    img_t = 255 * img_t # Now scale by 255\n",
        "    img_t = img_t.astype(np.uint8)\n",
        "    cv2.imwrite(testA_Folder+\"/\"+short_name[0]+\"_\"+str(t)+\".png\", img_t)\n",
        "    cv2.imwrite(testB_Folder+\"/\"+short_name[0]+\"_\"+str(t)+\".png\", img_t)\n",
        "\n",
        "# Here we create a merged A / A image for the prediction\n",
        "  os.chdir(\"/content\")\n",
        "  !python pytorch-CycleGAN-and-pix2pix/datasets/combine_A_and_B.py --fold_A \"$imageA_folder\" --fold_B \"$imageB_folder\" --fold_AB \"$imageAB_folder\"\n",
        "\n",
        "# Pix2pix functions\n",
        "def pix2pix_WF(imageAB_folder, Prediction_model_name, Prediction_model_path, Image_min_dim, patch_size, checkpoint, saving_folder):\n",
        "\n",
        "  os.chdir(\"/content\")\n",
        "  !python pytorch-CycleGAN-and-pix2pix/test.py --dataroot \"$imageAB_folder\" --name \"$Prediction_model_name\" --model pix2pix --no_dropout --preprocess resize_and_crop --load_size $load_size --crop_size $crop_size --results_dir \"$saving_folder\" --checkpoints_dir \"$Prediction_model_path\" --num_test $n_timepoint --epoch $checkpoint --input_nc \"1\" --output_nc \"1\" --dataset_mode \"aligned\"\n",
        "\n",
        "  Checkpoint_name = \"test_\"+str(checkpoint)\n",
        "\n",
        "  Prediction_results_folder = saving_folder+\"/\"+Prediction_model_name+\"/\"+Checkpoint_name+\"/images\"\n",
        "\n",
        "  Prediction_results_images = os.listdir(Prediction_results_folder)\n",
        "\n",
        "  for f in Prediction_results_images:\n",
        "    if (f.endswith(\"_fake_B.png\")):\n",
        "      shutil.copyfile(Prediction_results_folder+\"/\"+f,saving_folder+\"/\"+f)\n",
        "\n",
        "  shutil.rmtree(saving_folder+\"/\"+Prediction_model_name)\n",
        "\n",
        "\n",
        "def generate_stack(input_folder, Saving_folder):\n",
        "# Here we check the image dimensions\n",
        "  random_choice = random.choice(os.listdir(input_folder))\n",
        "  x = io.imread(input_folder+\"/\"+random_choice)\n",
        "  Image_Y = x.shape[0]\n",
        "  Image_X = x.shape[1]\n",
        "\n",
        "#Here we load all the images as a stack to generate the projection\n",
        "  n_images = len([name for name in os.listdir(input_folder)])\n",
        "  image_stack = np.zeros((n_images, Image_Y, Image_X))\n",
        "  Images_name = os.listdir(input_folder)\n",
        "  for t in range(n_images):\n",
        "    Image_t = io.imread(input_folder+\"/\"+Images_name[t], as_gray= True)\n",
        "    image_stack[t] = Image_t\n",
        "  os.chdir(Saving_folder)\n",
        "  imsave(str(short_name[0])+\"_stack.tif\", image_stack)\n",
        "\n",
        "def load_images_from_folder(folder, Saving_folder):\n",
        "    images = []\n",
        "    # Find all the files in the folder\n",
        "    for filename in os.listdir(folder):\n",
        "        # Only consider files that end with .jpg (or modify to suit your file types)\n",
        "        if filename.endswith(\".png\"):\n",
        "            img = io.imread(os.path.join(folder, filename), as_gray= True)\n",
        "            if img is not None:\n",
        "                # Remove the common prefix from filename\n",
        "                filename = filename.replace(short_name[0], \"\")\n",
        "                # Get the number from the file name using regex\n",
        "                number = re.search(r'(\\d+)', filename)\n",
        "                if number is not None:\n",
        "                    images.append((int(number.group()), img))  # Use the matched number for sorting\n",
        "    # Sort images according to the number in their name\n",
        "    images.sort(key=lambda x: x[0])\n",
        "    # Take only image data, discarding the numbers\n",
        "    images = [img for num, img in images]\n",
        "    # Stack images\n",
        "    stacked_images = np.stack(images)\n",
        "    os.chdir(Saving_folder)\n",
        "    imsave(str(short_name[0])+\"_pix2pixstack.tif\", stacked_images)\n",
        "    del stacked_images\n",
        "\n",
        "def combinelabels(Result_folder):\n",
        "  StarDist_BF = io.imread(Saving_folder_StarDist_cancer_cells_BF +\"/\"+short_name[0] +\".tif\")\n",
        "  StarDist_Both = io.imread(Saving_folder_StarDist_cancer_cells_both +\"/\"+short_name[0] +\".tif\")\n",
        "  StarDist_pix2pix = io.imread(Saving_folder_StarDist_cancer_cells_pix2pix +\"/\"+short_name[0] +\".tif\")\n",
        "\n",
        "  StarDist_BF[StarDist_BF>0]=1\n",
        "  StarDist_Both[StarDist_Both>0]=1\n",
        "  StarDist_pix2pix[StarDist_pix2pix>0]=1\n",
        "\n",
        "  label = StarDist_BF+StarDist_Both+StarDist_pix2pix\n",
        "  os.chdir(Result_folder)\n",
        "  imsave(str(short_name[0])+\"combined_labels.tif\", label, compression ='zlib')\n",
        "  label[label>0]=1\n",
        "  imsave(str(short_name[0])+\"combined_mask.tif\", label, compression ='zlib')\n",
        "  return label\n",
        "\n",
        "def final_seg(Results_folder, save_Final):\n",
        "    video_path = os.path.join(Results_folder, short_name[0], f\"{short_name[0]}combined_mask.tif\")\n",
        "    video = io.imread(video_path)\n",
        "    video = (255 * video).astype(np.uint8)\n",
        "\n",
        "    n_timepoint = video.shape[0]\n",
        "    prediction_stack = np.zeros((n_timepoint, video.shape[1], video.shape[2]), dtype=np.float32)\n",
        "\n",
        "    # Analyze each time points one after the other\n",
        "    for t in range(n_timepoint):\n",
        "        image = video[t]\n",
        "        distance = ndi.distance_transform_edt(image)\n",
        "        coords = peak_local_max(distance, footprint=np.ones((3, 3)), labels=image)\n",
        "        mask = np.zeros(distance.shape, dtype=bool)\n",
        "        mask[tuple(coords.T)] = True\n",
        "        markers, _ = ndi.label(mask)\n",
        "        prediction_stack[t] = watershed(-distance, markers, mask=image)\n",
        "\n",
        "    prediction_stack = img_as_float32(prediction_stack, force_copy=False)\n",
        "\n",
        "    os.chdir(save_Final)\n",
        "    imsave(str(short_name[0])+\"final_mask.tif\", prediction_stack, compression ='zlib')\n",
        "\n",
        "    fig, axes = plt.subplots(ncols=3, figsize=(9, 3), sharex=True, sharey=True)\n",
        "    ax = axes.ravel()\n",
        "\n",
        "    ax[0].imshow(video[1], cmap=plt.cm.gray)\n",
        "    ax[0].set_title('Overlapping objects')\n",
        "    ax[1].imshow(-distance, cmap=plt.cm.gray)\n",
        "    ax[1].set_title('Distances')\n",
        "    ax[2].imshow(prediction_stack[1], cmap=plt.cm.nipy_spectral)\n",
        "    ax[2].set_title('Separated objects')\n",
        "\n",
        "    for a in ax:\n",
        "        a.set_axis_off()\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plotresults(Result_folder):\n",
        "  lbl_cmap = random_label_cmap()\n",
        "\n",
        "  StarDist_BF = io.imread(Saving_folder_StarDist_cancer_cells_BF +\"/\"+short_name[0] +\".tif\")\n",
        "  StarDist_Both = io.imread(Saving_folder_StarDist_cancer_cells_both +\"/\"+short_name[0] +\".tif\")\n",
        "  StarDist_pix2pix = io.imread(Saving_folder_StarDist_cancer_cells_pix2pix +\"/\"+short_name[0] +\".tif\")\n",
        "\n",
        "  f=plt.figure(figsize=(16,8))\n",
        "  plt.subplot(2,3,1)\n",
        "  plt.imshow(timelapse_WF[0], cmap=\"gray\", interpolation='nearest')\n",
        "  plt.title('BF')\n",
        "  plt.axis('off');\n",
        "  plt.subplot(2,3,2)\n",
        "  plt.imshow(timelapse_both[0], cmap=\"gray\", interpolation='nearest')\n",
        "  plt.title('Both Channel')\n",
        "  plt.axis('off');\n",
        "  plt.subplot(2,3,3)\n",
        "  plt.imshow(timelapse_pix2pix[0],cmap=\"gray\", interpolation='nearest')\n",
        "  plt.title('Pix2Pix predictions')\n",
        "  plt.axis('off');\n",
        "  plt.subplot(2,3,4)\n",
        "  plt.imshow(StarDist_BF[0], cmap=lbl_cmap, interpolation='nearest')\n",
        "  plt.title('StarDist_BF')\n",
        "  plt.axis('off');\n",
        "  plt.subplot(2,3,5)\n",
        "  plt.imshow(StarDist_Both[0], cmap=lbl_cmap, interpolation='nearest')\n",
        "  plt.title('StarDist_Both')\n",
        "  plt.axis('off');\n",
        "  plt.subplot(2,3,6)\n",
        "  plt.imshow(StarDist_pix2pix[0], cmap=lbl_cmap, interpolation='nearest')\n",
        "  plt.title('StarDist_pix2pix')\n",
        "  plt.axis('off');\n",
        "  plt.savefig(Result_folder+'/'+str(short_name[0])+'_results.png',bbox_inches='tight',pad_inches=0)\n",
        "  plt.show()\n",
        "\n",
        "print('----------------------------')\n",
        "print(\"Libraries installed\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLYcZR9gMv42"
      },
      "source": [
        "# **6. Select your parameters and paths**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "y2TD5p7MZrEb"
      },
      "outputs": [],
      "source": [
        "latest = \"latest\"\n",
        "\n",
        "#@markdown #Provide the path to your dataset:\n",
        "\n",
        "BF_folder = \"/content/gdrive/Shareddrives/Kurppa_colab/Data_to_process/6.4Results_stagreg_1024/BF-corrected\" #@param {type:\"string\"}\n",
        "Both_folder = \"/content/gdrive/Shareddrives/Kurppa_colab/Data_to_process/6.4Results_stagreg_1024/both-corrected\" #@param {type:\"string\"}\n",
        "Results_folder = \"/content/gdrive/Shareddrives/Kurppa_colab/Data_to_process/240523_results\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown #StarDist models locations:\n",
        "\n",
        "StarDist_model_cancer_cells_BF = \"/content/gdrive/Shareddrives/Kurppa_colab/Stardist_BF_round_cells/3-models/Stardist_BF_round_cell_200aug\" #@param {type:\"string\"}\n",
        "StarDist_model_both = \"/content/gdrive/Shareddrives/Kurppa_colab/StarDist-fluorescence_training/3-model/Kurppa-Stardist-200e+aug\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "#@markdown #Pix2pix models locations:\n",
        "\n",
        "\n",
        "Pix2pix_model_BF_to_both = \"/content/gdrive/Shareddrives/Kurppa_colab/Pix2pix/3_model/pix2pix-kurppa-400-1740pairs-3\" #@param {type:\"string\"}\n",
        "\n",
        "Pix2pix_model_Nuclei_checkpoint = 50#@param {type:\"raw\"}\n",
        "\n",
        "\n",
        "# Here we check that the StarDist BF models exist\n",
        "\n",
        "StarDist_cancer_cells_BF_model_name = os.path.basename(StarDist_model_cancer_cells_BF)\n",
        "StarDist_cancer_cells_BF_model_path = os.path.dirname(StarDist_model_cancer_cells_BF)\n",
        "\n",
        "StarDist_cancer_cells_BF_full_model_path = StarDist_cancer_cells_BF_model_path+'/'+StarDist_cancer_cells_BF_model_name+'/'\n",
        "\n",
        "# Here we check that the pix2pix models exist\n",
        "if os.path.exists(StarDist_cancer_cells_BF_full_model_path):\n",
        "  print(\"The \"+StarDist_cancer_cells_BF_model_name+\" network will be used to detect round cancer cells in BF image.\")\n",
        "else:\n",
        "  print(bcolors.WARNING+'!! WARNING: The chosen StarDist model for detecting the cancer cells does not exist !!'+W)\n",
        "  print('Please make sure you provide a valid model path and model name before proceeding further.')\n",
        "\n",
        "StarDist_model_both_name = os.path.basename(StarDist_model_both)\n",
        "StarDist_model_both_path = os.path.dirname(StarDist_model_both)\n",
        "\n",
        "StarDist_model_both_full_model_path = StarDist_model_both_path+'/'+StarDist_model_both_name+'/'\n",
        "\n",
        "# Here we check that the pix2pix models exist\n",
        "if os.path.exists(StarDist_model_both_full_model_path):\n",
        "  print(\"The \"+StarDist_model_both_name+\" network will be used to detect cancer cells in the both image.\")\n",
        "else:\n",
        "  StarDist_model_cells_name = \"fluo\"\n",
        "\n",
        "#Here we find the loaded model name and parent path\n",
        "Pix2pix_model_Nuclei_model_name = os.path.basename(Pix2pix_model_BF_to_both)\n",
        "Pix2pix_model_Nuclei_model_path = os.path.dirname(Pix2pix_model_BF_to_both)\n",
        "\n",
        "#here we check if the pix2pix model exists\n",
        "Pix2pix_model_Nuclei_full_model_path = Pix2pix_model_Nuclei_model_path+'/'+Pix2pix_model_Nuclei_model_name+'/'\n",
        "\n",
        "if os.path.exists(Pix2pix_model_Nuclei_full_model_path):\n",
        "  print(\"The \"+Pix2pix_model_Nuclei_model_name+\" network will be used to predict fluo image from bf image.\")\n",
        "else:\n",
        "  W  = '\\033[0m'  # white (normal)\n",
        "  R  = '\\033[31m' # red\n",
        "  print(R+'!! WARNING: The chosen model does not exist !!'+W)\n",
        "  print('Please make sure you provide a valid model path and model name before proceeding further.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "R4tHDCLNK-QS"
      },
      "outputs": [],
      "source": [
        "#@markdown #Let's go\n",
        "\n",
        "from skimage import io, img_as_float32\n",
        "from scipy import ndimage as ndi\n",
        "from skimage.segmentation import watershed\n",
        "from skimage.feature import peak_local_max\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "#create path for the final sequences\n",
        "save_Final = Results_folder+\"/\"+ \"final_mask\"\n",
        "\n",
        "if os.path.exists(save_Final):\n",
        "  shutil.rmtree(save_Final)\n",
        "os.makedirs(save_Final)\n",
        "\n",
        "#Here we perform the predictions\n",
        "\n",
        "for image in os.listdir(BF_folder):\n",
        "\n",
        "  print(\"Performing prediction on: \"+image)\n",
        "\n",
        "  #here we open the two required dataset\n",
        "\n",
        "  timelapse_WF = io.imread(BF_folder+\"/\"+image)\n",
        "  timelapse_both = io.imread(Both_folder+\"/\"+image)\n",
        "\n",
        "\n",
        "  #here we get info on the images\n",
        "  short_name = os.path.splitext(image)\n",
        "  Image_Y = timelapse_WF.shape[1]\n",
        "  Image_X = timelapse_WF.shape[2]\n",
        "  n_timepoint = timelapse_WF.shape[0]\n",
        "\n",
        "  load_size = 1024 #change here to change the output for pix2pix\n",
        "  #Image_min_dim = 992 #change here to change the output for pix2pix\n",
        "\n",
        "  crop_size = 1024\n",
        "  #patch_size = 992\n",
        "\n",
        "# here we create the folder where to save the data\n",
        "\n",
        "  Saving_folder = Results_folder+\"/\"+short_name[0]\n",
        "\n",
        "  if os.path.exists(Saving_folder):\n",
        "    shutil.rmtree(Saving_folder)\n",
        "  os.makedirs(Saving_folder)\n",
        "\n",
        " # Here we actually start analysing the data\n",
        "\n",
        "  #pix2pix predictions.\n",
        "\n",
        "  #here we prepare the folder for pix2pix\n",
        "\n",
        "  Saving_path_pix2pix = \"/content/pix2pix\"\n",
        "  if os.path.exists(Saving_path_pix2pix):\n",
        "    shutil.rmtree(Saving_path_pix2pix)\n",
        "  os.makedirs(Saving_path_pix2pix)\n",
        "\n",
        "\n",
        "  imageA_folder = Saving_path_pix2pix+\"/Raw/A\"\n",
        "  os.makedirs(imageA_folder)\n",
        "\n",
        "  imageB_folder = Saving_path_pix2pix+\"/Raw/B\"\n",
        "  os.makedirs(imageB_folder)\n",
        "\n",
        "  imageAB_folder = Saving_path_pix2pix+\"/Raw/AB\"\n",
        "  os.makedirs(imageAB_folder)\n",
        "\n",
        "  testAB_Folder = Saving_path_pix2pix+\"/Raw/AB/test\"\n",
        "  os.makedirs(testAB_Folder)\n",
        "\n",
        "  testA_Folder = Saving_path_pix2pix+\"/Raw/A/test\"\n",
        "  os.makedirs(testA_Folder)\n",
        "\n",
        "  testB_Folder = Saving_path_pix2pix+\"/Raw/B/test\"\n",
        "  os.makedirs(testB_Folder)\n",
        "\n",
        "  Saving_path_pix2pix_WF_DAPI = Saving_path_pix2pix +\"/predictions\"\n",
        "  os.makedirs(Saving_path_pix2pix_WF_DAPI)\n",
        "\n",
        "  #pix2pix prepare the data\n",
        "  pix2pix_prepare_data(timelapse_WF)\n",
        "\n",
        "  #pix2pix nuclei\n",
        "  pix2pix_WF(imageAB_folder, Pix2pix_model_Nuclei_model_name, Pix2pix_model_Nuclei_model_path, load_size, crop_size, Pix2pix_model_Nuclei_checkpoint, Saving_path_pix2pix_WF_DAPI)\n",
        "\n",
        "  #create a stack from pix2pix prediction.\n",
        "\n",
        "  #generate_stack(Saving_path_pix2pix_WF_DAPI, Saving_path_pix2pix)\n",
        "  load_images_from_folder(Saving_path_pix2pix_WF_DAPI, Saving_folder)\n",
        "\n",
        "  #StarDist predictions.\n",
        "\n",
        "  #Here we identify the cancer cells from the BF data\n",
        "\n",
        "  Saving_folder_StarDist_cancer_cells_BF = Saving_folder+\"/\"+\"Cancer_cells_BF\"\n",
        "  if os.path.exists(Saving_folder_StarDist_cancer_cells_BF):\n",
        "    shutil.rmtree(Saving_folder_StarDist_cancer_cells_BF)\n",
        "  os.makedirs(Saving_folder_StarDist_cancer_cells_BF)\n",
        "\n",
        "  stardist(timelapse_WF, Saving_folder_StarDist_cancer_cells_BF, StarDist_cancer_cells_BF_model_name, StarDist_cancer_cells_BF_model_path)\n",
        "\n",
        "\n",
        "  #StarDist predictions. Here we identify the cancer cells from the both channel\n",
        "\n",
        "  Saving_folder_StarDist_cancer_cells_both = Saving_folder+\"/\"+\"Cancer_cells_both\"\n",
        "  if os.path.exists(Saving_folder_StarDist_cancer_cells_both):\n",
        "    shutil.rmtree(Saving_folder_StarDist_cancer_cells_both)\n",
        "  os.makedirs(Saving_folder_StarDist_cancer_cells_both)\n",
        "\n",
        "  stardist(timelapse_both, Saving_folder_StarDist_cancer_cells_both, StarDist_model_both_name, StarDist_model_both_path)\n",
        "\n",
        "  #StarDist predictions. Here we identify the cancer cells from the pix2pix prediction\n",
        "\n",
        "  Saving_folder_StarDist_cancer_cells_pix2pix = Saving_folder+\"/\"+\"Cancer_cells_pix2pix\"\n",
        "  if os.path.exists(Saving_folder_StarDist_cancer_cells_pix2pix):\n",
        "    shutil.rmtree(Saving_folder_StarDist_cancer_cells_pix2pix)\n",
        "  os.makedirs(Saving_folder_StarDist_cancer_cells_pix2pix)\n",
        "\n",
        "  timelapse_pix2pix = io.imread(Saving_folder+\"/\"+short_name[0]+\"_pix2pixstack.tif\")\n",
        "\n",
        "  stardist(timelapse_pix2pix, Saving_folder_StarDist_cancer_cells_pix2pix, StarDist_model_both_name, StarDist_model_both_path)\n",
        "\n",
        "  # make a figure\n",
        "  plotresults(Saving_folder)\n",
        "\n",
        "  # combine the labels\n",
        "\n",
        "  combinelabels(Saving_folder)\n",
        "\n",
        "  # watershed\n",
        "  #final_seg(Results_folder,save_Final)\n",
        "\n",
        "  # Final StarDist\n",
        "\n",
        "  video_path = os.path.join(Results_folder, short_name[0], f\"{short_name[0]}combined_mask.tif\")\n",
        "  video = io.imread(video_path)\n",
        "\n",
        "  stardist(video, save_Final, pretrained_model_name, \"/content\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}